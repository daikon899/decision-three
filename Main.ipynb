{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1116,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import math\n",
    "from collections import Counter\n",
    "import random\n",
    "import operator\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "df = pd.read_csv('adult.data')\n",
    "df.columns.values[0] = 'age'\n",
    "df.columns.values[1] = 'workclass'\n",
    "df.columns.values[2] = 'fnlwgt'\n",
    "df.columns.values[3] = 'education'\n",
    "df.columns.values[4] = 'education_num'\n",
    "df.columns.values[5] = 'marital_status'\n",
    "df.columns.values[6] = 'occupation'\n",
    "df.columns.values[7] = 'relationship'\n",
    "df.columns.values[8] = 'race'\n",
    "df.columns.values[9] = 'sex'\n",
    "df.columns.values[10] = 'capital_gain'\n",
    "df.columns.values[11] = 'capital_loss'\n",
    "df.columns.values[12] = 'hours_per_week'\n",
    "df.columns.values[13] = 'native_country'\n",
    "df.columns.values[14] = 'target'\n",
    "\n",
    "df = df.drop(columns=['fnlwgt'])\n",
    "df = df.drop(columns=['capital_gain'])\n",
    "df = df.drop(columns=['capital_loss'])\n",
    "df = df[df.workclass != ' ?']\n",
    "df = df[df.occupation != ' ?']\n",
    "df = df[df.native_country != ' ?']\n",
    "df.loc[df['native_country'] != ' United-States', 'native_country'] = 'Foreign-Country'\n",
    "for i in range(0, max(df['age']), 5):\n",
    "    df.loc[df['age'] == i + 1, 'age'] = i\n",
    "    df.loc[df['age'] == i + 2, 'age'] = i\n",
    "    df.loc[df['age'] == i + 3, 'age'] = i\n",
    "    df.loc[df['age'] == i + 4, 'age'] = i\n",
    "for i in range(0, max(df['hours_per_week']), 10):\n",
    "    df.loc[df['hours_per_week'] == i + 1, 'hours_per_week'] = i\n",
    "    df.loc[df['hours_per_week'] == i + 2, 'hours_per_week'] = i\n",
    "    df.loc[df['hours_per_week'] == i + 3, 'hours_per_week'] = i\n",
    "    df.loc[df['hours_per_week'] == i + 4, 'hours_per_week'] = i\n",
    "    df.loc[df['hours_per_week'] == i + 5, 'hours_per_week'] = i\n",
    "    df.loc[df['hours_per_week'] == i + 6, 'hours_per_week'] = i\n",
    "    df.loc[df['hours_per_week'] == i + 7, 'hours_per_week'] = i\n",
    "    df.loc[df['hours_per_week'] == i + 8, 'hours_per_week'] = i\n",
    "    df.loc[df['hours_per_week'] == i + 9, 'hours_per_week'] = i\n",
    "\n",
    "attributes = df.columns.tolist()\n",
    "attributes.remove('target')\n",
    "training_set, test_set = train_test_split(df, test_size=0.2)\n",
    "training_set, validation_set = train_test_split(df, test_size=0.33)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Learning tree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1117,
   "metadata": {},
   "outputs": [],
   "source": [
    "def attr_domain(attribute, examples):\n",
    "    return examples[attribute].drop_duplicates()\n",
    "\n",
    "\n",
    "def attr_domain(attribute, examples):\n",
    "    return examples[attribute].drop_duplicates()\n",
    "\n",
    "\n",
    "class Node:\n",
    "    def __init__(self, attribute):\n",
    "        self.attribute = attribute\n",
    "        self.branch = {}\n",
    "\n",
    "\n",
    "def plurality_value(examples):  # returns most common target value\n",
    "    c = Counter(examples.target).most_common(2)\n",
    "    if c[1][0] == c[1][1]:\n",
    "        return Node(c[0][random.randint(0, 1)])\n",
    "    else:\n",
    "        return Node(c[0][0])\n",
    "\n",
    "\n",
    "def importance(attributes, examples):\n",
    "    def bool_entropy(q):  # B(q)\n",
    "        if q == 0 or q == 1:\n",
    "            return 0\n",
    "        return -(q * math.log(q, 2) + (1 - q) * math.log(1 - q, 2))\n",
    "\n",
    "    def expected_entropy(attribute, examples):  # Remainder(A)\n",
    "        sum = 0.0\n",
    "        for k in attr_domain(attribute, examples):\n",
    "            ek = examples[examples[attribute] == k]\n",
    "            pk = len(ek[ek['target'] == ' >50K'])\n",
    "            nk = len(ek[ek['target'] == ' <=50K'])\n",
    "            q = float(pk) / float(pk + nk)\n",
    "            sum += float(len(ek)) / len(examples) * bool_entropy(q)\n",
    "        return sum\n",
    "\n",
    "    gain_list = []  # list of Gain(A)\n",
    "    for a in attributes:\n",
    "        gain_list.append(\n",
    "            bool_entropy(len(examples[examples['target'] == ' >50K']) / float(len(examples))) - expected_entropy(a,\n",
    "                                                                                                                 examples))\n",
    "\n",
    "    index, value = max(enumerate(gain_list), key=operator.itemgetter(1))\n",
    "    return attributes[index]\n",
    "\n",
    "\n",
    "def decision_tree_learning(examples, attributes, parent_examples=()):\n",
    "    if len(examples) == 0:\n",
    "        return plurality_value(parent_examples)\n",
    "    elif len(set(examples.target)) == 1:  # if same classification\n",
    "        return Node(examples.iat[0, len(examples.columns) - 1])\n",
    "    elif len(attributes) == 0:\n",
    "        return plurality_value(examples)\n",
    "    else:\n",
    "        A = importance(attributes, examples)\n",
    "        tree = Node(A)\n",
    "        a = list(attributes)\n",
    "        a.remove(A)\n",
    "        for v in attr_domain(A, examples):\n",
    "            exs = examples[examples[A] == v]\n",
    "            tree.branch[v] = decision_tree_learning(exs, a, examples)\n",
    "        return tree\n",
    "\n",
    "dtree = decision_tree_learning(training_set, attributes)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1118,
   "metadata": {},
   "outputs": [],
   "source": [
    "def to_rules(tree):\n",
    "    def visit(node, path):\n",
    "        if len(node.branch) != 0:  # not leaf\n",
    "            for branch in node.branch:\n",
    "                path.append([node.attribute, branch])\n",
    "                visit(node.branch[branch], path)\n",
    "                path.pop()\n",
    "        else:\n",
    "            p = list(path)\n",
    "            p.append(['target', node.attribute])\n",
    "            rules.append(p)\n",
    "    rules = []\n",
    "    path = []\n",
    "    visit(tree, path)\n",
    "    return rules\n",
    "\n",
    "\n",
    "def test_rules(dataset, rules):\n",
    "    l = len(dataset)\n",
    "    total_score = 0\n",
    "    single_score = []\n",
    "    for rule in rules:\n",
    "        ds = dataset\n",
    "        for r in rule[:-1]:\n",
    "            ds = ds[ds[r[0]] == r[1]]\n",
    "        r = rule[-1]\n",
    "        hits = len(ds[ds['target'] == r[1]])\n",
    "        total_score += hits\n",
    "        if len(ds) == 0:\n",
    "            single_score.append(0.5)\n",
    "        else:\n",
    "            single_score.append(float(hits) / len(ds))\n",
    "        dataset = dataset.drop(ds.index.tolist(), axis=0)\n",
    "    return float(total_score) / l, single_score\n",
    "\n",
    "\n",
    "def test_dtree(dtree):\n",
    "    rules = to_rules(dtree)\n",
    "    ts, p = test_rules(test_set, rules)\n",
    "    return ts\n",
    "\n",
    "accuracy = test_dtree(dtree)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Pruning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def rules_pruning():\n",
    "    def hitrate(rule, dataset):  # returns 0 if rule is not long enough\n",
    "        ds = dataset\n",
    "        if rule is None or len(rule) <= 2:\n",
    "            return 0\n",
    "        for r in rule[:-1]:\n",
    "            ds = ds[ds[r[0]] == r[1]]\n",
    "        r = rule[-1]\n",
    "        total_score = len(ds[ds['target'] == r[1]])\n",
    "        if len(ds) == 0:\n",
    "            return 0.5\n",
    "        return float(total_score) / len(ds)\n",
    "\n",
    "    def index_to_prune(rule, score_to_beat):\n",
    "        if rule is None or len(rule) <= 2:\n",
    "            return None\n",
    "        candidate = None\n",
    "        for i in range(len(rule[:-1])):\n",
    "            hp_rule = list(rule)\n",
    "            hp_rule.pop(i)\n",
    "            hr = hitrate(hp_rule, validation_set)\n",
    "            if hr > score_to_beat:\n",
    "                candidate = i\n",
    "                score_to_beat = hr\n",
    "        return candidate\n",
    "\n",
    "    accuracy, percentages = test_rules(validation_set, rules)\n",
    "    for i in range(len(percentages)):\n",
    "        original_rule = list(rules[i])\n",
    "        print('progress:', i, '/', len(percentages) - 1)\n",
    "        if percentages[i] < 1:\n",
    "            j = index_to_prune(rules[i], percentages[i])\n",
    "            if j is not None:\n",
    "                rules[i].pop(j)\n",
    "                new_accuracy, new_percentages = test_rules(validation_set, rules)\n",
    "                if accuracy >= new_accuracy:\n",
    "                    rules[i] = original_rule    # turn back\n",
    "                else:\n",
    "                    print (accuracy, '->', new_accuracy)\n",
    "                    accuracy = new_accuracy\n",
    "                    percentages = new_percentages\n",
    "                \n",
    "rules = to_rules(dtree)\n",
    "rules_pruning()\n",
    "accuracy_prun, p = test_rules(test_set, rules)\n",
    "print('Score before pruning -> ', accuracy)\n",
    "print('Score after pruning -> ', accuracy_prun)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
