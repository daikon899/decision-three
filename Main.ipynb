{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Learning Tree Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {},
   "outputs": [],
   "source": [
    "def attr_domain(attribute, examples):\n",
    "    return examples[attribute].drop_duplicates()\n",
    "\n",
    "\n",
    "class Node:\n",
    "    def __init__(self, attribute):\n",
    "        self.attribute = attribute\n",
    "        self.branch = {}\n",
    "\n",
    "\n",
    "def plurality_value(examples):  # gests most common target value\n",
    "    c = Counter(examples.target).most_common(2)\n",
    "    if c[1][0] == c[1][1]:\n",
    "        return Node(c[0][random.randint(0, 1)])\n",
    "    else:\n",
    "        return Node(c[0][0])\n",
    "\n",
    "\n",
    "def importance(attributes, examples):\n",
    "    def bool_entropy(q):  # B(q)\n",
    "        if q == 0 or q == 1:\n",
    "            return 0\n",
    "        return -(q * math.log(q, 2) + (1 - q) * math.log(1 - q, 2))\n",
    "\n",
    "    def expected_entropy(attribute, examples):  # Remainder(A)\n",
    "        sum = 0.0\n",
    "        for k in attr_domain(attribute, examples):\n",
    "            ek = examples[examples[attribute] == k]\n",
    "            pk = len(ek[ek['target'] == ' >50K'])\n",
    "            nk = len(ek[ek['target'] == ' <=50K'])\n",
    "            q = float(pk) / float(pk + nk)\n",
    "            sum += float(len(ek)) / len(examples) * bool_entropy(q)\n",
    "        return sum\n",
    "\n",
    "    gain_list = []  # list of Gain(A)\n",
    "    for a in attributes:\n",
    "        gain_list.append(\n",
    "            bool_entropy(len(examples[examples['target'] == ' >50K']) / float(len(examples))) - expected_entropy(a,\n",
    "                                                                                                                 examples))\n",
    "    index, value = max(enumerate(gain_list), key=operator.itemgetter(1))\n",
    "    return attributes[index]\n",
    "\n",
    "\n",
    "def decision_tree_learning(examples, attributes, parent_examples=()):\n",
    "    if len(examples) == 0:\n",
    "        return plurality_value(parent_examples)\n",
    "    elif len(set(examples.target)) == 1:  # if same classification\n",
    "        return Node(examples.iat[0, len(examples.columns) - 1])\n",
    "    elif len(attributes) == 0:\n",
    "        return plurality_value(examples)\n",
    "    else:\n",
    "        A = importance(attributes, examples)\n",
    "        tree = Node(A)\n",
    "        a = list(attributes)\n",
    "        a.remove(A)\n",
    "        for v in attr_domain(A, examples):\n",
    "            exs = examples[examples[A] == v]\n",
    "            tree.branch[v] = decision_tree_learning(exs, a, examples)\n",
    "        return tree\n",
    "    \n",
    "     \n",
    "def to_rules(tree):     # convert the tree to DNF rules\n",
    "    def visit(node, path):\n",
    "        if len(node.branch) != 0:\n",
    "            for branch in node.branch:\n",
    "                path.append([node.attribute, branch])\n",
    "                visit(node.branch[branch], path)\n",
    "                path.pop()\n",
    "        else:\n",
    "            p = list(path)\n",
    "            p.append(['target', node.attribute])\n",
    "            rules.append(p)\n",
    "    rules = []\n",
    "    path = []\n",
    "    visit(tree, path)\n",
    "    return rules"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Preprocess Adult Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib notebook\n",
    "import pandas as pd\n",
    "import math\n",
    "from collections import Counter\n",
    "import random\n",
    "import operator\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "df = pd.read_csv('adult.data')\n",
    "\n",
    "df.columns = ['age', 'workclass', 'fnlwgt', 'education', 'education_num', 'marital_status', 'occupation', 'relationship', 'race', 'sex', 'capital_gain', 'capital_loss', 'hours_per_week', 'native_country', 'target']\n",
    "df = df.drop(columns=['fnlwgt'])\n",
    "df = df.drop(columns=['capital_gain'])\n",
    "df = df.drop(columns=['capital_loss'])\n",
    "df = df[df.workclass != ' ?']\n",
    "df = df[df.occupation != ' ?']\n",
    "df = df[df.native_country != ' ?']\n",
    "df.loc[df['native_country'] != ' United-States', 'native_country'] = 'Foreign-Country'\n",
    "df['age'] =  (pd.cut(df['age'], bins=5))\n",
    "df['hours_per_week'] = (pd.cut(df['hours_per_week'], bins=5))\n",
    "attributes = df.columns.tolist()\n",
    "attributes.remove('target')\n",
    "training_set, test_set = train_test_split(df, test_size=0.2)\n",
    "training_set, validation_set = train_test_split(df, test_size=0.33)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Pruning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "metadata": {},
   "outputs": [],
   "source": [
    "def rules_pruning(limit):\n",
    "    def rule_lengths():\n",
    "        l = []\n",
    "        for rule in rules:\n",
    "            l.append(len(rule))\n",
    "        return l\n",
    "\n",
    "    def errors(rule):\n",
    "        vs = validation_set\n",
    "        if rule is None or len(rule) <= 2:\n",
    "            return 100000\n",
    "        for r in rule[:-1]:\n",
    "            vs = vs[vs[r[0]] == r[1]]\n",
    "        r = rule[-1]\n",
    "        e = len(vs[vs['target'] != r[1]])\n",
    "        return e\n",
    "\n",
    "    def score(rule):\n",
    "        if len(rule) == 0:\n",
    "            return 0\n",
    "        vs = validation_set\n",
    "        for r in rule[:-1]:\n",
    "            vs = vs[vs[r[0]] == r[1]]\n",
    "        total = len(vs)\n",
    "        r = rule[-1]\n",
    "        correct = len(vs[vs['target'] == r[1]])\n",
    "        if total == 0:\n",
    "            return 0\n",
    "        return float(correct) / total\n",
    "\n",
    "    def best_r(original_rule):  # sceglie la miglior r da togliere\n",
    "        if len(original_rule) == 0:\n",
    "            return False\n",
    "        scores = []\n",
    "        for r in original_rule[:-1]:\n",
    "            rule = list(original_rule)\n",
    "            rule.remove(r)\n",
    "            scores.append(score(rule))\n",
    "        return original_rule[(scores.index(max(scores)))]\n",
    "\n",
    "    def change_rule_target(rule):\n",
    "        if len(rule) == 0:\n",
    "            return 0\n",
    "        vs = validation_set\n",
    "        for r in rule[:-1]:\n",
    "            vs = vs[vs[r[0]] == r[1]]\n",
    "        r = rule[-1]\n",
    "        if len(vs) > 0:\n",
    "            r[1] = Counter(vs.target).most_common()[0][0]\n",
    "        return 0\n",
    "\n",
    "    def is_in(smaller, bigger):  # Note: does not check last value\n",
    "        if len(smaller) == 0 or len(bigger) == 0:\n",
    "            return False\n",
    "        for s in smaller[:-1]:\n",
    "            match = False\n",
    "            for b in bigger[:-1]:\n",
    "                if s == b:\n",
    "                    match = True\n",
    "                    break\n",
    "            if not match:\n",
    "                return False\n",
    "        return True\n",
    "\n",
    "    def pruning(index):  # pruning of rules[index]\n",
    "        if len(rules[index]) <= 2:\n",
    "            return False\n",
    "        original_rule = list(rules[index])\n",
    "        r = best_r(rules[index])\n",
    "        rules[index].remove(r)\n",
    "        change_rule_target(rules[index])\n",
    "        err_pruned = errors(rules[index])\n",
    "\n",
    "        err_non_pruned = 0\n",
    "        for rule in rules:\n",
    "            if rules[index] != rule and is_in(rules[index], rule):\n",
    "                err_non_pruned += errors(rule)\n",
    "        err_non_pruned += errors(original_rule)\n",
    "        if err_pruned >= err_non_pruned:  # turn back\n",
    "            rules[index] = original_rule\n",
    "            return False\n",
    "        else:\n",
    "            return True\n",
    "\n",
    "\n",
    "    lengths = rule_lengths()\n",
    "    while sum(lengths) != 0:\n",
    "        max_l = max(lengths)\n",
    "        if max_l <= limit:\n",
    "            break\n",
    "        for i in range(len(rules)):\n",
    "            if lengths[i] == max_l:  # chooses only rules with length max_l\n",
    "                p = pruning(i)\n",
    "                if p:  # cleanup\n",
    "                    lengths[i] -= 1\n",
    "                    for l in range(len(rules)):\n",
    "                        if is_in(rules[i], rules[l]) and i != l:\n",
    "                            lengths[l] = 0\n",
    "                            rules[l] = []\n",
    "                else:\n",
    "                    lengths[i] = 0\n",
    "    for i in reversed(range(len(rules))):\n",
    "        if len(rules[i]) == 0:\n",
    "            rules.pop(i)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "metadata": {},
   "outputs": [],
   "source": [
    "dtree = decision_tree_learning(training_set, attributes)\n",
    "rules = to_rules(dtree)\n",
    "rules_pruning(4)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
